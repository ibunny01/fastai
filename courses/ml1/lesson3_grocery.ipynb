{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grocery Store Competition\n",
    "Brick-and-mortar grocery stores are always in a delicate dance with purchasing and sales forecasting. Predict a little over, and grocers are stuck with overstocked, perishable goods. Guess a little under, and popular items quickly sell out, leaving money on the table and customers fuming.\n",
    "\n",
    "The problem becomes more complex as retailers add new locations with unique needs, new products, ever transitioning seasonal tastes, and unpredictable product marketing. Corporación Favorita, a large Ecuadorian-based grocery retailer, knows this all too well. They operate hundreds of supermarkets, with over 200,000 different products on their shelves.\n",
    "\n",
    "Corporación Favorita has challenged the Kaggle community to build a model that more accurately forecasts product sales. They currently rely on subjective forecasting methods with very little data to back them up and very little automation to execute plans. They’re excited to see how machine learning could better ensure they please customers by having just enough of the right products at the right time.\n",
    "\n",
    "[Corporación Favorita Grocery Sales Forecasting](https://www.kaggle.com/c/favorita-grocery-sales-forecasting)\n",
    "\n",
    "* this is current, so we won't work on it as a group\n",
    "* predict items on shelf based on\n",
    "* oil prices, stores, locations\n",
    "* ability to explain the problem is very important\n",
    "* key: what are independent variables- how many units of each kind of product are sold on each store on each day during a 2 week period?\n",
    "* dependent, info we have to predict it: how many units of each product of each store on each day was sold;\n",
    "* what metadata is there (oil price) --> our relational dataset\n",
    "* Stars schema https://www.kaggle.com/c/favorita-grocery-sales-forecasting/data\n",
    "* Snowflake schema: might have more info on the items\n",
    "* Jeremy's notebook: tmp-grocery.ipynb\n",
    "\n",
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T03:05:04.049352Z",
     "start_time": "2018-01-23T03:05:04.020888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T03:05:05.444320Z",
     "start_time": "2018-01-23T03:05:04.348346Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T03:41:55.919218Z",
     "start_time": "2018-01-23T03:41:55.761254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holidays_events.csv  oil.csv\t\t    stores.csv\ttrain.csv\r\n",
      "items.csv\t     sample_submission.csv  test.csv\ttransactions.csv\r\n"
     ]
    }
   ],
   "source": [
    "PATH = \"data/grocery-sales/\"\n",
    "!ls {PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read data\n",
    "* read in data\n",
    "* limit memory = False --> use as much memory to figure out what kinds of data are here; you'll run out of memory here\n",
    "* to limit the amount of space, create a dictionary for each column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T03:41:56.992701Z",
     "start_time": "2018-01-23T03:41:56.951782Z"
    }
   },
   "outputs": [],
   "source": [
    "types = {'id': 'int64',\n",
    "'item_nbr': 'int32',\n",
    "'store_nbr': 'int8',\n",
    "'unit_sales': 'float32',\n",
    "'onpromotion': 'object'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this dataset has 125 million rows\n",
    "\n",
    "use head function to look at small amount of data; determine the data types and set it up in a dictionary called \"types\" (see above)\n",
    "\n",
    "or read in small dataset and let pandas figure it out for you\n",
    "\n",
    "can now read in data in less than 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T03:44:01.730285Z",
     "start_time": "2018-01-23T03:41:57.385561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min, sys: 3.37 s, total: 2min 4s\n",
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_all = pd.read_csv(f'{PATH}train.csv', parse_dates=['date'], dtype = types,\n",
    "                    infer_datetime_format = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:54:07.787495Z",
     "start_time": "2018-01-23T04:53:51.542402Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all.onpromotion.fillna(False, inplace=True)\n",
    "df_all.onpromotion = df_all.onpromotion.map({'False': False, 'True': True})\n",
    "df_all.onpromotion = df_all.onpromotion.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:45:20.022256Z",
     "start_time": "2018-01-23T04:45:16.918792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.24 s, sys: 1.94 s, total: 4.17 s\n",
      "Wall time: 3.06 s\n"
     ]
    }
   ],
   "source": [
    "%time df_all.to_feather('tmp/raw_groceries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:46:07.237614Z",
     "start_time": "2018-01-23T04:45:29.776754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.8 s, sys: 584 ms, total: 37.4 s\n",
      "Wall time: 37.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.254970e+08</td>\n",
       "      <td>125497040</td>\n",
       "      <td>1.254970e+08</td>\n",
       "      <td>1.254970e+08</td>\n",
       "      <td>1.254970e+08</td>\n",
       "      <td>125497040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>118194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96028767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-15 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.274852e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.746458e+01</td>\n",
       "      <td>9.727692e+05</td>\n",
       "      <td>8.554856e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.622788e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.633051e+01</td>\n",
       "      <td>5.205336e+05</td>\n",
       "      <td>2.360515e+01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.699500e+04</td>\n",
       "      <td>-1.537200e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.137426e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>5.223830e+05</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.274852e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>9.595000e+05</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.412278e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.300000e+01</td>\n",
       "      <td>1.354380e+06</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.254970e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.400000e+01</td>\n",
       "      <td>2.127114e+06</td>\n",
       "      <td>8.944000e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                 date     store_nbr      item_nbr  \\\n",
       "count   1.254970e+08            125497040  1.254970e+08  1.254970e+08   \n",
       "unique           NaN                 1684           NaN           NaN   \n",
       "top              NaN  2017-07-01 00:00:00           NaN           NaN   \n",
       "freq             NaN               118194           NaN           NaN   \n",
       "first            NaN  2013-01-01 00:00:00           NaN           NaN   \n",
       "last             NaN  2017-08-15 00:00:00           NaN           NaN   \n",
       "mean    6.274852e+07                  NaN  2.746458e+01  9.727692e+05   \n",
       "std     3.622788e+07                  NaN  1.633051e+01  5.205336e+05   \n",
       "min     0.000000e+00                  NaN  1.000000e+00  9.699500e+04   \n",
       "25%     3.137426e+07                  NaN  1.200000e+01  5.223830e+05   \n",
       "50%     6.274852e+07                  NaN  2.800000e+01  9.595000e+05   \n",
       "75%     9.412278e+07                  NaN  4.300000e+01  1.354380e+06   \n",
       "max     1.254970e+08                  NaN  5.400000e+01  2.127114e+06   \n",
       "\n",
       "          unit_sales onpromotion  \n",
       "count   1.254970e+08   125497040  \n",
       "unique           NaN           2  \n",
       "top              NaN       False  \n",
       "freq             NaN    96028767  \n",
       "first            NaN         NaN  \n",
       "last             NaN         NaN  \n",
       "mean    8.554856e+00         NaN  \n",
       "std     2.360515e+01         NaN  \n",
       "min    -1.537200e+04         NaN  \n",
       "25%     2.000000e+00         NaN  \n",
       "50%     4.000000e+00         NaN  \n",
       "75%     9.000000e+00         NaN  \n",
       "max     8.944000e+04         NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df_all.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出Trainset的日期是从：\n",
    "\n",
    "2013-01-01 00:00:00 - 2017-08-15 00:00:00\n",
    "\n",
    "Testset from :\n",
    "\n",
    "2017-08-16 00:00:00 - 2017-08-31 00:00:00 (one day later)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:59:53.418082Z",
     "start_time": "2018-01-23T04:59:24.332287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.370464e+06</td>\n",
       "      <td>3370464</td>\n",
       "      <td>3.370464e+06</td>\n",
       "      <td>3.370464e+06</td>\n",
       "      <td>3370464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-27 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>210654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3370464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-16 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-31 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.271823e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.750000e+01</td>\n",
       "      <td>1.244798e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.729693e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.558579e+01</td>\n",
       "      <td>5.898362e+05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.254970e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.699500e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.263397e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>8.053210e+05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.271823e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.750000e+01</td>\n",
       "      <td>1.294665e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.280249e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.100000e+01</td>\n",
       "      <td>1.730015e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.288675e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.400000e+01</td>\n",
       "      <td>2.134244e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                 date     store_nbr      item_nbr  \\\n",
       "count   3.370464e+06              3370464  3.370464e+06  3.370464e+06   \n",
       "unique           NaN                   16           NaN           NaN   \n",
       "top              NaN  2017-08-27 00:00:00           NaN           NaN   \n",
       "freq             NaN               210654           NaN           NaN   \n",
       "first            NaN  2017-08-16 00:00:00           NaN           NaN   \n",
       "last             NaN  2017-08-31 00:00:00           NaN           NaN   \n",
       "mean    1.271823e+08                  NaN  2.750000e+01  1.244798e+06   \n",
       "std     9.729693e+05                  NaN  1.558579e+01  5.898362e+05   \n",
       "min     1.254970e+08                  NaN  1.000000e+00  9.699500e+04   \n",
       "25%     1.263397e+08                  NaN  1.400000e+01  8.053210e+05   \n",
       "50%     1.271823e+08                  NaN  2.750000e+01  1.294665e+06   \n",
       "75%     1.280249e+08                  NaN  4.100000e+01  1.730015e+06   \n",
       "max     1.288675e+08                  NaN  5.400000e+01  2.134244e+06   \n",
       "\n",
       "       onpromotion  \n",
       "count      3370464  \n",
       "unique           1  \n",
       "top           True  \n",
       "freq       3370464  \n",
       "first          NaN  \n",
       "last           NaN  \n",
       "mean           NaN  \n",
       "std            NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(f'{PATH}test.csv', parse_dates=['date'], dtype = types,\n",
    "                    infer_datetime_format = True)\n",
    "df_test.onpromotion.fillna(False, inplace=True)\n",
    "df_test.onpromotion = df_all.onpromotion.map({'False': False, 'True': True})\n",
    "df_test.onpromotion = df_all.onpromotion.astype(bool)\n",
    "df_test.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:02:50.173573Z",
     "start_time": "2018-01-23T05:02:50.118632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125497035</th>\n",
       "      <td>125497035</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>54</td>\n",
       "      <td>2089339</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125497036</th>\n",
       "      <td>125497036</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>54</td>\n",
       "      <td>2106464</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125497037</th>\n",
       "      <td>125497037</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>54</td>\n",
       "      <td>2110456</td>\n",
       "      <td>192.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125497038</th>\n",
       "      <td>125497038</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>54</td>\n",
       "      <td>2113914</td>\n",
       "      <td>198.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125497039</th>\n",
       "      <td>125497039</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>54</td>\n",
       "      <td>2116416</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id       date  store_nbr  item_nbr  unit_sales  onpromotion\n",
       "125497035  125497035 2017-08-15         54   2089339         4.0         True\n",
       "125497036  125497036 2017-08-15         54   2106464         1.0         True\n",
       "125497037  125497037 2017-08-15         54   2110456       192.0         True\n",
       "125497038  125497038 2017-08-15         54   2113914       198.0         True\n",
       "125497039  125497039 2017-08-15         54   2116416         2.0         True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_feather('tmp/raw_groceries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$NWRMSLE = \\sqrt{ \\frac{\\sum_{i=1}^n w_i \\left( \\ln(\\hat{y}_i + 1) - \\ln(y_i +1)  \\right)^2  }{\\sum_{i=1}^n w_i}}$$\n",
    "* in this competition，the **root mean squared log error** is the evaluation\n",
    "* there are some **negative sales** that we should consider them to be 0\n",
    "\n",
    "\n",
    "所以我们做如下变换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:07:05.086497Z",
     "start_time": "2018-01-23T05:07:02.218541Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all.unit_sales = np.log1p(np.clip(df_all.unit_sales, 0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:13:47.047484Z",
     "start_time": "2018-01-23T05:12:21.430536Z"
    }
   },
   "outputs": [],
   "source": [
    "add_datepart(df_all, 'date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:14:52.637964Z",
     "start_time": "2018-01-23T05:14:52.596637Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_vals(a, n):\n",
    "    return a[:n].copy(), a[n:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:15:42.284496Z",
     "start_time": "2018-01-23T05:15:37.139023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((122126576, 18), (3370464, 18))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_valid = len(df_test)\n",
    "n_trn = len(df_all) - n_valid\n",
    "train, valid = split_vals(df_all, n_trn)\n",
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, I didn't need to run `train_cats()`, because all of my data types are already numerical.\n",
    "\n",
    "If they weren't I would need to call `train_cast` and then I would need to call the `apply_cats` to apply the same categorical codes from the training set to the validation set：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_cats(raw_train)\n",
    "# apply_cats(raw_valid, raw_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`proc_df`: make a copy of the dataframe, grab the Y value, drop the dependent variable, from the original and then it's going to fix missing. so how do we fix missing? \n",
    ">if it's numeric then we fix it by basically saying let's first of all check that it does have some missing right? so if it does have some missing values then we're going to create a new column called `xxx_na`, and it's going to be a boolean column with a `1` anytime that was missing, and a `0` anytime it wasn't. Then replace the NAs(the missing) with the median. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:36:40.539220Z",
     "start_time": "2018-01-23T05:35:27.218356Z"
    }
   },
   "outputs": [],
   "source": [
    "trn, y, nas_trn = proc_df(train, 'unit_sales')\n",
    "val, y_val, nas_val = proc_df(valid, 'unit_sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先sample 1000000的小数据集来试试rf："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:42:47.346847Z",
     "start_time": "2018-01-23T05:42:47.298163Z"
    }
   },
   "outputs": [],
   "source": [
    "set_rf_samples(1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:42:29.333355Z",
     "start_time": "2018-01-23T05:36:44.694721Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.array(trn, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:42:31.897275Z",
     "start_time": "2018-01-23T05:42:31.619108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122126576, 17)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:42:31.587809Z",
     "start_time": "2018-01-23T05:42:29.730918Z"
    }
   },
   "outputs": [],
   "source": [
    "def rmse(x, y): \n",
    "    return math.sqrt(((x - y)**2).mean())\n",
    "\n",
    "def print_score(m):\n",
    "    res = [rmse(m.predict(x), y), rmse(m.predict(val), y_val), m.score(x, y), m.score(val, y_val)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there's no relationship between the size of the dataset(x) and how long it takes to build the random forests(time). their relationship is between the number of estimators(20) multiplied by the sample size(1_000_000).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* there are 120 million records; we probably don't want to create a tree; would take a long time\n",
    "* can start with 10K or 100K; Jeremy found 1 million is good size, runs in < 1 minute\n",
    "* there is no relationship between how large a dataset is and how long it takes to build a random forest\n",
    "* relationship is between number of estimators times sample size\n",
    "* n_jobs=8 number of cores it will use; Jeremy ran it on computer that had 60 cores, so make it smaller\n",
    "* n_jobs=-1 means use every single core\n",
    "* Jeremy converted dataframe into array of float32; internally inside random forest code, they do that anyway\n",
    "* by doing it once, saves time in the background to convert it to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:47:42.829549Z",
     "start_time": "2018-01-23T05:46:42.420765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 19s, sys: 12.5 s, total: 6min 32s\n",
      "Wall time: 1min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=100, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=8,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=20, min_samples_leaf=100, n_jobs=8)\n",
    "%time m.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `prun` runs profiler, tells you which line of code behind the scenes took the most time to run\n",
    "* *profiler* is a software engineering tool\n",
    "* cannot use oob_score when using set_rf_samples, because it will use 125 million - 1 million = 124 million too calculate oob_score, which will take forever\n",
    ">因为oob_score是out of bag score，也就是说用trainset中所有没有被sample的data来test得到score\n",
    "* wants validation set, which is the most recent date samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:55:07.802244Z",
     "start_time": "2018-01-23T05:54:08.531717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun m.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:49:31.826965Z",
     "start_time": "2018-01-23T05:48:10.940118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7650825024257072, 0.7656551271739643, 0.2473550581382178, 0.21977441813084242]\n"
     ]
    }
   ],
   "source": [
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[training RMSE , validation RMSE, training R^2, validation R^2, OOB R^2]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:59:51.278367Z",
     "start_time": "2018-01-23T05:56:52.794545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 16s, sys: 12.4 s, total: 7min 29s\n",
      "Wall time: 1min 7s\n",
      "[0.6855446149249788, 0.7021835899695322, 0.39571048986244917, 0.3437714104431948]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=20, min_samples_leaf=10, n_jobs=8)\n",
    "%time m.fit(x, y)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T06:03:19.261461Z",
     "start_time": "2018-01-23T05:59:51.281337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 43s, sys: 12.8 s, total: 7min 56s\n",
      "Wall time: 1min 12s\n",
      "[0.6611483982829707, 0.6934118503161113, 0.4379544570093905, 0.360064335905226]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=20, min_samples_leaf=3, n_jobs=8)\n",
    "%time m.fit(x, y)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很明显上面的rf model都不是很work: `rmsle≈0.7`。\n",
    "\n",
    "再看一下trainset，提供的信息太少了，我们还需要一些metadata（weather, store_location...）.\n",
    "\n",
    "one way of tackling this kind of problem is to create lots and lots of new columns containing things like: average number of sales on holidays, average percent change in sale, or between January and February and so on and so forth ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T06:03:19.905935Z",
     "start_time": "2018-01-23T06:03:19.264733Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Dayofweek</th>\n",
       "      <th>Dayofyear</th>\n",
       "      <th>Is_month_end</th>\n",
       "      <th>Is_month_start</th>\n",
       "      <th>Is_quarter_end</th>\n",
       "      <th>Is_quarter_start</th>\n",
       "      <th>Is_year_end</th>\n",
       "      <th>Is_year_start</th>\n",
       "      <th>Elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125497035</th>\n",
       "      <td>125497035</td>\n",
       "      <td>54</td>\n",
       "      <td>2089339</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>True</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1502755200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125497036</th>\n",
       "      <td>125497036</td>\n",
       "      <td>54</td>\n",
       "      <td>2106464</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>True</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1502755200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125497037</th>\n",
       "      <td>125497037</td>\n",
       "      <td>54</td>\n",
       "      <td>2110456</td>\n",
       "      <td>5.262690</td>\n",
       "      <td>True</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1502755200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125497038</th>\n",
       "      <td>125497038</td>\n",
       "      <td>54</td>\n",
       "      <td>2113914</td>\n",
       "      <td>5.293305</td>\n",
       "      <td>True</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1502755200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125497039</th>\n",
       "      <td>125497039</td>\n",
       "      <td>54</td>\n",
       "      <td>2116416</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>True</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1502755200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  store_nbr  item_nbr  unit_sales  onpromotion  Year  \\\n",
       "125497035  125497035         54   2089339    1.609438         True  2017   \n",
       "125497036  125497036         54   2106464    0.693147         True  2017   \n",
       "125497037  125497037         54   2110456    5.262690         True  2017   \n",
       "125497038  125497038         54   2113914    5.293305         True  2017   \n",
       "125497039  125497039         54   2116416    1.098612         True  2017   \n",
       "\n",
       "           Month  Week  Day  Dayofweek  Dayofyear  Is_month_end  \\\n",
       "125497035      8    33   15          1        227         False   \n",
       "125497036      8    33   15          1        227         False   \n",
       "125497037      8    33   15          1        227         False   \n",
       "125497038      8    33   15          1        227         False   \n",
       "125497039      8    33   15          1        227         False   \n",
       "\n",
       "           Is_month_start  Is_quarter_end  Is_quarter_start  Is_year_end  \\\n",
       "125497035           False           False             False        False   \n",
       "125497036           False           False             False        False   \n",
       "125497037           False           False             False        False   \n",
       "125497038           False           False             False        False   \n",
       "125497039           False           False             False        False   \n",
       "\n",
       "           Is_year_start     Elapsed  \n",
       "125497035          False  1502755200  \n",
       "125497036          False  1502755200  \n",
       "125497037          False  1502755200  \n",
       "125497038          False  1502755200  \n",
       "125497039          False  1502755200  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trick：there's a kaggle kernel that points out that what you could do is just take the last two weeks and take the average sales the by `onpromotion` by `store_nbr` by `item_nbr`, and just submit that, and you come about 30th. \n",
    "\n",
    "**How to start from this model, and make it a tiny bit better?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【Trick】there's one thing I'm going to let you use the *testset* for an addition and that is to calibrate your *validation set* so what Terrance did here was, he built 4 different models, some which he thought would be better than others and he submitted each of the four models to Kaggle to find out its score, and so the x-axis is the score the Kaggle produce on the leaderboard, and then on the y-axis he plotted the score on a particular *validation set* .\n",
    "\n",
    "he was trying out to see whether this validation said look like it was going to be any good, so if your validation set is good then the relationship between the leaderboards for by the testing score and your validation set score should lie in a straight line, ideally, it'll actually lie on the $y = x$ line, but honestly that doesn't matter too much as long as relatively speaking it tells you which models are better than which other models, then you know which model is the best right? and you know how it's going to perform on the testset, because you know the linear relationship between two things okay?\n",
    " \n",
    "\n",
    "\n",
    "<img src=\"images/validation_4_scores.png\" width=\"70%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
